{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2266187-df83-47a0-afad-1331eb8d87d3",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "In this notebook I define the model object for the Diffusion LM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0568787-98eb-4d56-9eb3-bab4b07f76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusion_lm.data import E2EDataset\n",
    "from diffusion_lm.model import DiffusionLM\n",
    "\n",
    "from diffusion_lm.utils import timestep_embedding, diffusion_noise_schedule\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0f71e6-d09f-4348-bb17-7c8cb4dbd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionLM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_model=\"bert-base-uncased\",\n",
    "        T=2000,  # diffusion steps\n",
    "        d=16,  # embedding dimensions\n",
    "        lr=1e-4,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(base_model)\n",
    "        self.embedding = nn.Embedding(self.tokenizer.vocab_size, d)\n",
    "        self.bert_config = BertConfig()\n",
    "        self.encoder = BertEncoder(self.bert_config)\n",
    "        self.hidden_dim = d\n",
    "        self.diffusion_steps = T\n",
    "        self.time_embed_dim = 4 * d\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = self.bert_config.hidden_size\n",
    "        self.LayerNorm = nn.LayerNorm(\n",
    "            self.hidden_size, eps=self.bert_config.layer_norm_eps\n",
    "        )\n",
    "\n",
    "        # Add time embedding\n",
    "        self.time_embedding = nn.Sequential(\n",
    "            nn.Linear(d, self.time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.time_embed_dim, self.hidden_size),\n",
    "        )\n",
    "\n",
    "        # Calculate timestep embeddings\n",
    "        self.timestep_embeddings = self.get_timestep_embeddings()\n",
    "\n",
    "        # Add position embeddings\n",
    "        self.register_buffer(\n",
    "            \"position_ids\",\n",
    "            torch.arange(self.bert_config.max_position_embeddings).expand((1, -1)),\n",
    "        )\n",
    "        self.position_embeddings = nn.Embedding(\n",
    "            self.bert_config.max_position_embeddings, self.hidden_size\n",
    "        )\n",
    "\n",
    "        # Downsample input vector\n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(d, self.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "        )\n",
    "\n",
    "        # Downsample output vector\n",
    "        self.output_projection = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden_size, 2 * d),\n",
    "        )\n",
    "\n",
    "    def get_timestep_embeddings(self):\n",
    "        timesteps = torch.arange(self.diffusion_steps)\n",
    "        timesteps = timestep_embedding(timesteps, self.hidden_dim)\n",
    "        timesteps = self.time_embedding(timesteps)\n",
    "        return timesteps\n",
    "\n",
    "    def q_sample(self, x, T):\n",
    "        \"\"\"\n",
    "        Otherwise known as q\n",
    "        \"\"\"\n",
    "        n_batches, seq_length, embed_dim = x.shape\n",
    "\n",
    "        # Repeat x along time dimension T times\n",
    "        x_t = einops.repeat(x, \"b s x -> b t s x\", t=2000)\n",
    "\n",
    "        # Calculate and propagate noise schedule\n",
    "        beta_t = torch.Tensor(diffusion_noise_schedule(np.arange(T)))\n",
    "        beta_t = einops.repeat(\n",
    "            beta_t, \"t -> b t w x\", b=n_batches, w=seq_length, x=embed_dim\n",
    "        )\n",
    "\n",
    "        # Generate noised samples\n",
    "        q_t = torch.normal(\n",
    "            (1 - torch.sqrt(beta_t)) * x_t, std=1 - torch.sqrt(1 - beta_t)\n",
    "        )\n",
    "\n",
    "        return q_t\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        \"\"\"\n",
    "        Otherwise known as p\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert text to tokens\n",
    "        n_batches, n_timesteps, seq_length, embed_dim = embeddings.shape\n",
    "\n",
    "        # Upsample to `hidden_size` dimensional embeddings\n",
    "        upsampled = self.input_projection(embeddings)\n",
    "        logging.debug(f\"upsampled.shape: {upsampled.shape}\")\n",
    "\n",
    "        # Add timestep embedding + unroll across each sequence\n",
    "        timesteps = einops.repeat(\n",
    "            timesteps, \"t e -> b t s e\", b=n_batches, s=seq_length\n",
    "        )\n",
    "        logging.debug(f\"timestep.shape: {timesteps.shape}\")\n",
    "\n",
    "        # Calculate positional embedding\n",
    "        position_embeddings = self.position_embeddings(\n",
    "            self.position_ids[:, :seq_length]\n",
    "        )\n",
    "        logging.debug(f\"position_embeddings.shape: {position_embeddings.shape}\")\n",
    "\n",
    "        # Apply dropout + layernorm\n",
    "        encoder_inputs = self.dropout(\n",
    "            self.LayerNorm(upsampled + timesteps + position_embeddings)\n",
    "        )\n",
    "\n",
    "        # Get `hidden_size`-dimensional bert representation\n",
    "        encoder_inputs = einops.rearrange(encoder_inputs, \"b t s x -> (b t) s x\")\n",
    "\n",
    "        encoded = self.encoder(encoder_inputs).last_hidden_state\n",
    "        logging.debug(f\"encoded.shape: {encoded.shape}\")\n",
    "\n",
    "        # Downsample to d-representation\n",
    "        downsampled = self.output_projection(encoded)\n",
    "\n",
    "        return downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2f505f9-a4e9-4900-84dd-0a1e659603cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset e2e_nlg (/home/kakapo/.cache/huggingface/datasets/e2e_nlg/default/0.0.0/bfeceb720929c2705bd227d1cfe5eaaab102a0bdac10dad618dac1e00c737430)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d529644351aa45d9b28475367cef6971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DiffusionLM()\n",
    "e2e_dataset = E2EDataset(\"train\")\n",
    "e2e_dataloader = DataLoader(e2e_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eed28e4-17a4-41b0-a6a2-10277e89d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion time step\n",
    "batch = next(iter(e2e_dataloader))\n",
    "embeddings = model.embedding(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f512676-c95b-471b-94f0-49bac822428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a7c10c7d-e6e0-4397-9476-51beeb745162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
